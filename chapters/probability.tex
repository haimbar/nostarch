\hypertarget{ch:probability}{%
  \chapter{Probability -- Intuition and Paradoxes}
  \label{ch:probability}}

\chapterartfile{images/static/Black_Dice_PNG_Clip_Art-2653.png}
\hypertarget{Randomworld}{The world is random and probability is a tool to quantify the randomness. It's the mathematical basis for all statistical reasoning. It helps us to determine how likely it is that we'll win a lottery, or the chances that our town will be hit by an earthquake in the next month.
However, probability theory can be confusing and even counter-intuitive in some cases. In this chapter we review basic concepts in probability, we show some examples in which our intuition may fail us (and even the best mathematician), and provide guidance how to avoid common errors in probabilistic thinking.}

\hypertarget{probability}{%
\section{Probability}\label{probability}}
\subsection{Basic Definitions}
%We will go through examples to see how probability helps interpret phenomena in real life and how probability may counter intuition. We begin by introducing some concepts:
We begin with some essential terminology and notation: 
\begin{itemize}
\item Experiment: a situation in which the outcome occurs randomly, e.g.,
  flipping a coin, rolling a dice, and picking a card from a deck.
\item Sample Space: the set of all possible outcomes in an experiment, e.g.,
  \{head, tail\}, \{1, 2, ..., 6\}, and \{all card faces\}.
\item Event: a subset of the sample space is called an event; an event
  occurs if the outcome from an experiment belong to the subset of sample space. For example, if
  you roll a die, and you are interested in the result of having an even number,
  then the event is $E$=\{2, 4, 6\}.
\end{itemize}

The relationship between a sample space and an event can be illustrated using a
Venn diagram such as Figure~\ref{fig:probability-event} for rolling a die. The
sample space labeled as $S$ is represented by the outer rectangle that contains all the
six possible outcomes. The event $E$ of rolling an even number is represented
by the inner, rounded rectangle  that contains the numbers 2, 4, and 6.

\begin{figure}[H]
\begin{tikzpicture}
  \draw (-2, 2) rectangle (2, 0);
  \draw[rounded corners=10pt, fill = cyan!20, draw=blue] (-0.7,0.1) rectangle ++(2.5,0.8);
  \draw (-1.5, 1.7) node{$S$};
  \draw (-1, 1.2) node{1} (0, 1.2) node{3} (1, 1.2) node{5};
  \draw (-0.5, 0.5) node{2} (0.5, 0.5) node{4} (1.5, 0.5) node{6};
  \draw[text = blue] (0, 0.3) node{$E$};
\end{tikzpicture}
\caption{Sample space (the outcomes of a fair six-sided die) and event (rolling an even number) illustrated with Venn diagram}
\label{fig:probability-event}
\end{figure}

\emph{Probability} is a number between zero and one which tells us how likely an event to occur. If we assume (for now) that the sample space is finite and each possible outcome in an experiment  has an equal chance to occur, then the probability of event $E$ is
  \begin{equation}
    P(E) =\frac{\text{size of } E}{\text{size of } S}.
  \end{equation}
  In the example depicted in Figure~\ref{fig:probability-event} the probability that we roll an even number when we use a fair die, is $P(even)=3/6=0.5$.
  
In the following chapters we will deal with infinite (even uncountable) sample spaces, and we will generalize the definition of $P(E)$ then.
  
 \begin{example}[Elevator waiting time]
  Mr. Smith works on the 13th floor of a 15 floor building. The only elevator in his building  moves continuously through floors 1, 2, . . . 14, 15, 14, . . . 2, 1, 2,  . . . , except that it stops on a floor on which the button has been
  pressed. Assume that time spent loading and unloading passengers is very small
  compared to the traveling time.  Mr.~Smith complains that at 5pm, when he
  wants to go home, the elevator almost always goes up when it stops on his
  floor. What is the explanation?
\end{example}

When Mr.~Smith gets to the elevator, it may be below the 13th floor or above
it. The elevator will go up if it is below the 13th floor and it will go
down if it is above the 13th floor. There are 12 floors below the 13th floor and
2 floors above it, so the probability that the elevator is below the 13th floor
is $12/14\approx0.86>0.5$. Thus no matter when Mr. Smith wants to go home, it is
more likely that the elevator is going up.

We can simulate this situation:

\showCode{R}{Code/probability-elevator.R}
\runR{Code/probability-elevator.R}{elevator}{}
Running the above code should give:
\includeOutput{elevator}

  
\hypertarget{conditional}{%
\subsection{Conditional Probability}\label{conditional}}

When there are two events $A$ and $B$ under consideration, knowing that $A$ has occurred may change the probability for $B$ to occur. For example, suppose that someone rolls a die behind a curtain and tells us only that the number is less than or equal to 3. What is the probability that it is an even number? Given that we got 1, 2, or 3, the only possibility that it is even is if the number is 2. The \emph{unconditional} probability of getting an even number in a roll of a die is 1/2, but because of the information that provided to us, we conclude that the \emph{conditional} probability is 1/3. 
Using mathematical notation, we write  $P(B\mid A)=1/3$ which stands for ``conditional on $A$=the number is less than or equal to 3, the probability of $B$=the number is even, is 1/3''. 

Once again, it is helpful to visualize such things using a Venn diagram. In Figure~\ref{fig:probability-conditional}, the sample space $S$ consists of the six possible outcomes and the two events are depicted as a circle (event $A$) and as a rounded rectangle ($B$). To say that we condition on $A$ means that we restrict our view and look only at outcomes that could occur if we are told that $A$ has occurred. In other words, our sample space becomes $A$, instead of the whole set, $S$.

\begin{figure}[htbp]
\begin{tikzpicture}[thick,fill opacity=0.5]
  \draw (-2, 2) rectangle (2.5, -0.5);
\draw[fill=MidnightBlue!80, draw=MidnightBlue] (-0.5, 1.05) circle (0.8);
  \draw[rounded corners=10pt, fill = Dandelion!80, draw=Dandelion] (-0.7,0.1) rectangle ++(2.5,0.8);
  \draw (-1.7, 1.7) node{$S$};
  \draw (-1, 1.2) node{1} (0, 1.2) node{3} (1, 1.2) node{5};
  \draw (-0.5, 0.5) node{2} (0.5, 0.5) node{4} (1.5, 0.5) node{6};
  \draw[text = orange] (1.2, -0.1) node{$B$};
  \draw[text = MidnightBlue] (-1.2, 0.5) node{$A$};
\end{tikzpicture}
\caption{Conditional probability -- given that we are told that a die gave a number less than or equal to 3 (event $A$), what is the probability that we got an even number ($B$)?}
\label{fig:probability-conditional}
\end{figure}

\bigskip
Can it be that we are told that some event $A$ has occurred, but this information tells us nothing about the probability of another event, $B$? Yes -- in this case we say that the two events are \emph{independent}, and we have
$$P(B\mid A) = P(B)\,.$$

For example, Abby rolls a fair die, while her roommate Amelia tosses a fair coin at the same time. If $A$ is the event `Abby got a 6' and $B$ is the event `Amelia got Heads', then $P(B\mid A) = 1/2$ because Abby's result has no impact on Amelia's. 

Sometimes establishing that two events are independent is harder. For example,
in general, the probability that Abby gets a text message within any given hour
is 0.7, and Amelia's is 0.6. Given that Abby got a text between 8 and 9am, does
it change the probability that Amelia got a text during the same hour? It may
depend on other (latent) events. For example, if they are late paying the rent,
then it is quite reasonable that Amelia will get a text from their landlord at
approximately the same time as Abby. 

Another related notion is that of `mutually exclusive' events. For example, suppose that
the Golden State Warriors and the Boston Celtics make it to the NBA finals. If
$A$ =  the Golden State Warriors will win the NBA championship next season, and
$B$ = the Boston Celtics will win the NBA championship next season, then these
events cannot occur at the same time. Mutually exclusive events are not independent. In
this example, if we somehow know that $A$ has happened, then we know for sure
that $B$ will not. Moreover, if we assign a probability of 0.6 that the Golden
State Warriors will win, then we know that $P(B) = 0.4$. 

\begin{example}[Two Children]
Consider the following two problems:
\begin{enumerate}
\item Mr. Jones has two children. The older child is a girl. What is the
  probability that both children are girls?
\item Mr. Smith has two children. At least one of them is a girl. What is the
  probability that both children are girls?
\end{enumerate}
\end{example}
In a family with two children there are four possible combinations of boy/girl
when we take into consideration their ages: \{Boy, Boy\}, \{Boy, Girl\}, \{Girl,
Boy\}, and \{Girl, Girl\}. Suppose that they all have the same probability to
occur.

For the first question: the sample space for the given situation consists of only two events -- \{Girl, Boy\}, \{Girl, Girl\}; and only one of them corresponds to the event of having two girls. Thus the
probability of two girls is 1/2. This question can also be solved this
way: since the older child is a girl, the probability of two girls is the
probability that the younger child is a girl which is 1/2.

For the second question, the sample space includes three possibilities: \{Boy, Girl\}, \{Girl, Boy\}, \{Girl, Girl\}. Thus the
probability of having two girls, given that at least one of them is a girl, is 1/3.

If we simulate many families, we can find the numerical answer quite accurately.

\showCode{R}{Code/probability-TwoChildren.R}
\runR{Code/probability-TwoChildren.R}{TwoChildren}{}
Running the above code should give:
\includeOutput{TwoChildren}





\subsection{Bayes' Rule}\label{Bayes}
One of the most important results in probability and statistics looks deceivingly simple, but has deep consequences, as we'll see in some of the subsequent examples. It is called Bayes' Rule, named after the reverend Thomas Bayes who discovered it in the 18th century. Consider two events, $A$ and $B$, such that $P(A)$ is greater than zero. Then
\begin{equation}\label{eq:bayes}
  P(B\mid A) = \frac{P(A\mid B)P(B)}{P(A)}.
\end{equation}
This formula is very useful when the conditional probability $P(B\mid A)$ is
difficult to find but the conditional probability $P(A\mid B)$ as well as the
unconditional probabilities are easy to find.

 \begin{example}[Football or ballet?]
Jane has season tickets to the home games of her town's football team, which she
attends 80\% of the time, and she also has season tickets to the town's ballet
which she attends 20\% of the time. If she attends the ballet in a week, she
will flip a fair coin to decide if she will attend the football game.
% In 10\% of the weeks she attends both the weekly football game and the ballet. 
This is depicted in Figure~\ref{fig:bayes-rule}, which shows that $P(F)=0.8$ and
$P(B)=0.2$. If we see Jane in the ballet, what is the probability that we'll see
her in the game in the same week?

% If we see her in the ballet, what is the probability that we will see her in the football game, as well?
% With Bayes' rule we get $P(A\mid B) =0.125\times0.8/0.2=0.5$.
% So, although Jane goes to  80\% of the football games, if she ends up going to the ballet then she is less likely to go to the game in the same week (50\%). 
\end{example}

We know that if we see her in a game, then the probability of seeing her in the
ballet is $P(B \mid F)=0.5$. Using Bayes' rule, $P(F\mid B)
=0.5\times0.2/0.8=0.125$.

\begin{figure}[H]
\begin{tikzpicture}[fill opacity=0.7]
  \draw (0,3) rectangle (4, 0);
  \draw[fill = red!80, draw=red] (1, 0.5) rectangle ++(2,2) node[midway,white]{F};
  \draw[fill = blue!80, draw=blue] (0.5,0.5) rectangle ++(1,1)  node[midway,white]{B};
\end{tikzpicture}
\caption{Bayes' rule. $F$ is the event that Jane attends the weekly football game, and $B$ is the events that she attends the weekly ballet}
\label{fig:bayes-rule}
\end{figure}



\begin{example}[Bertrand's Box]
Bertrand's box paradox was first posed by Joseph Bertrand in 1889. Here's the
question: there are three boxes, one contains two gold coins, one contains two
silver coins, and one contains a gold coin and a silver coin.
A box is selected at random and a coin is taken from that box at random. If the
coin is a gold coin, what's the probability that the other coin in that box is
also a gold coin?
\end{example}

This problem is about conditional probability. It's easy to find the
probability of getting a certain box, and it is easy to find the probability of
getting a gold coin if we know the box, as shown in
Figure~\ref{fig:probability-flow}. However, it is non-trivial to find the
probability of getting a certain box after we take out just one coin.
%when we know the final coin.
We see the six
possible outcomes in Figure~\ref{fig:probability-flow} are equally likely to
occur. Two outcomes of a gold coin are through the path of the box with two gold
coins and one outcome of a gold coin is through the path of the box with a gold
coin and a silver coin. Thus the answer to this problem is 2/3.

\begin{figure}[H]
\resizebox{0.6\columnwidth}{!}{%
\begin{tikzpicture}[%scale=0.5,
  edge from parent/.style={draw,-latex},
    boxes/.style={star, draw=none, fill=red, drop shadow, text centered, anchor=north},
    state/.style={draw=none, fill=red, circle, drop shadow, text centered, anchor=north},
    leaf/.style={draw=none, fill=orange, ellipse, text centered, anchor=north},
    leafs/.style={draw=none, fill=gray, ellipse, text centered, anchor=north},
    level distance=0.9cm, growth parent anchor=south
]
\node [boxes] {Boxes} [->] [sibling distance=4cm]
child{ [sibling distance=2cm]
  node [state] {Gold, Gold}
  child{node [leaf] {Gold}
    edge from parent{node[left]{$\frac{1}{2}$}}
  }
  child{node [leaf] {Gold}
    edge from parent{node[right]{$\frac{1}{2}$}}
  }
  edge from parent{node[above right]{$\frac{1}{3}$}}
}
child{ [sibling distance=2cm]
  node [state] {Gold, Silver}
  child{node [leaf] {Gold}
    edge from parent{node[left]{$\frac{1}{2}$}}
  }
  child{node [leafs] {Silver}
    edge from parent{node[right]{$\frac{1}{2}$}}
  }
  edge from parent [dashed] {node[right]{$\frac{1}{3}$}}
}
child{ [sibling distance=2cm]
  node [state] {Silver, Silver}
  child{node [leafs] {Silver}
    edge from parent{node[left]{$\frac{1}{2}$}}
  }
  child{node [leafs] {Silver}
    edge from parent{node[right]{$\frac{1}{2}$}}
  }
  edge from parent [dashed] {node[above right]{$\frac{1}{3}$}}
};
\end{tikzpicture}
}
\caption{Probability flow for Bertrand's Box}
\label{fig:probability-flow}
\end{figure}

This problem can also be solved using the Bayesian formula in
(\ref{eq:bayes}). Let $A$ be the event of getting a gold coin and $B$ be the
event of getting a box with two gold coins, then $P(A)=1/2$,
$P(B)=1/3$, and $P(A|B)=1$. Now the probability of a box with two gold
coins given a final gold coin is 
\begin{align}
  P(B\mid A) = \frac{P(A\mid B)P(B)}{P(A)}
  = \frac{1\times\frac{1}{3}}{\frac{1}{2}}
  =\frac{2}{3}.
\end{align}

Both of the aforementioned approaches give us the correct answer. However,
we don't have to go through the counting or reasoning. If we can simulate the
game, we can find the result pretty accurately. The following code simulates the 
game and approximate the probability numerically.

\showCode{R}{Code/probability-BertrandBox.R}
\runR{Code/probability-BertrandBox.R}{BertrandBox}{}
Running the above code should give:
\includeOutput{BertrandBox}

\section{When Intuition May Fail}
Probability-based logic may be confusing and even counter-intuitive in some cases. In this section, we show such cases, some of which have confused some of the brightest people. The purpose of introducing these examples is to show how they may occur in everyday situations, and how to deal with them correctly.

\hypertarget{Intransitive-Dice}{%
  \subsection{Intransitivity -- when $A>B$ and $B>C$ does not imply $A>C$}\label{Intransitive-Dice}}
Real numbers are transitive, meaning that if we know that $x>y$ and $y>z$ then $x>z$. However, probabilities of events are not always transitive. 
\begin{example}[Intransitive Dice]
We have three unusual dice:
\begin{itemize}
\item Die A has sides 2, 2, 4, 4, 9, 9.
\item Die B has sides 1, 1, 6, 6, 8, 8.
\item Die C has sides 3, 3, 5, 5, 7, 7.
\end{itemize}
\end{example}

To play a game you and your opponent choose two of the dice, say, A and B, and you get to choose which die you roll (and your opponent will roll the other.) The one who tolls a larger number wins. Which die do you want to choose?

Let's tabulate the possible results if dice A and B were chosen, and see which  die is preferred.
\begin{table}[H]
  \begin{tabular}{cc|ccc}
    \toprule
    &   & \multicolumn{3}{c}{B} \\
    &   & 1                & 6                & 8                \\
    \midrule
    \multirow{3}{*}{A}
    & 2 & \color{red}$A>B$ & $A<B$            & $A<B$            \\
    & 4 & \color{red}$A>B$ & $A<B$            & $A<B$            \\
    & 9 & \color{red}$A>B$ & \color{red}$A>B$ & \color{red}$A>B$ \\
    \bottomrule
  \end{tabular}
\end{table}
Since die A wins five out of the nine possible results and all possible results
occur with equal probability, we know that die A has a higher winning
probability (5/9) than die B. We should choose die A over die B.

Now suppose we choose dice B and C.
\begin{table}[H]
  \begin{tabular}{cc|ccc}
    \toprule
    &   & \multicolumn{3}{c}{B}                       \\
    &   & 1                & 6                & 8     \\
    \midrule
    \multirow{3}{*}{C}
    & 3 & \color{red}$C>B$ & $C<B$            & $C<B$ \\
    & 5 & \color{red}$C>B$ & $C<B$            & $C<B$ \\
    & 7 & \color{red}$C>B$ & \color{red}$C>B$ & $C<B$ \\
    \bottomrule
  \end{tabular}
\end{table}
We see that die B has a higher winning probability (5/9) than die C,
so we should choose die B over die C.

Since we should choose die A over die B, and choose die B over die C, does this
mean that we should choose die A over die C if these two dice are to be
selected? Surprisingly, the answer is NO. Here is the table of the possible
results.
\begin{table}[H]
  \begin{tabular}{cc|ccc}
    \toprule
    &   & \multicolumn{3}{c}{C} \\
    &   & 3                & 5                & 7                \\
    \midrule
    \multirow{3}{*}{A}
    & 2 & $A<C$            & $A<C$            & $A<C$            \\
    & 4 & \color{red}$A>C$ & $A<C$            & $A<C$            \\
    & 9 & \color{red}$A>C$ & \color{red}$A>C$ & \color{red}$A>C$ \\
    \bottomrule
  \end{tabular}
\end{table}
We should choose die C over die A!

Here is an experiment to simulate the intransitive dice.

\showCode{R}{Code/probability-IntransitiveDice.R}
Running this code should give the following:
\runR{Code/probability-IntransitiveDice.R}{IntransitiveDice}{}
\includeOutput{IntransitiveDice}


You are probably never going to encounter such dice, or play this game, but you may encounter a similar situation in real life when you have to choose among different people for a single position, or choose among similar products, based on preferences or ratings.
For example, suppose you want to purchase a new phone which is offered by three manufacturers, and there are six reviews for each phone. Note that the average ratings of all three options in our made-up example is the same. You may prefer phone A because it got the highest rating (twice). However, it also got two very low ratings, so choosing based on the maximum is risky. Option C has less variability in its ratings, but it didn't get a very high score from any reviewer. Furthermore, it may be that you have 60,000 reviews for each phone, and not just six. So, going systematically over the reviews is impractical, and you may decide that the best way to choose your phone is to use a randomized algorithm like the one in the dice example. That is, choose two of the options, and  then choose one random rating for each one, and select the one that give the highest score. This is a reasonable algorithm, but you have to be aware of the fact that when choices are made based on a probabilistic approach, ordering of options may not have the transitive property.



\hypertarget{birthday-problem}{%
  \subsection{Seemingly Rare Events}\label{birthday-problem}}

\begin{example}[Birthday Problem]\label{exam:birthday}
You go on a long trip on your birthday and take a bus. There are 23 people on
the bus, and to make the ride more fun you ask all the other passengers for
their birth date (month and day, not year) and see if you can celebrate
together. How likely is it that someone on the bus shares your birthday? How
likely are there at least two of the other 23 people who share a birthday (even
if it's not the same as yours)?
\end{example}

The chance that a random person has the same birthday as yours is
$1/365\approx0.0027$, so this is a rare event.
With 23 other people on the bus, the probability that someone shares your
birthday is about $0.061$ which is quite small, so it is pretty unlikely. For
the second question that two of the 23 people share a birthday, it seems that
the answer is similar, but the actually probability is surprisingly much
higher. The probability that at least two people share a birthday is about 0.5.

If you took a plane with 253 passengers, the probability that someone shares
your birthday is around 0.5. But you are almost certain that at least two people
share a birthday on that plane, because the probability is almost one.

% We will also answer the following question: what is the probability that on the bus/plane there are at least two people who share a birthday (even if it's not the same as yours)?

Let's use simulation to find answers to these questions.

\showCode{R}{Code/probability-birthday.R}
\runR{Code/probability-birthday.R}{birthday}{} Running the above code gives
results which are very close to the number we stated above, as predicted by
probability. That is, if there are 23 other people on the bus the probability
that some person's birthday is the same as yours is
\inlnR{```cat(prob.p23[1])```} and the probability that some other people share
the same birthday is \inlnR{```cat(prob.p23[2])```} . If there are 253 people on
the plane, the two probabilities are \inlnR{```cat(prob.p253[1])```} and
\inlnR{```cat(prob.p253[2])```}, respectively.

This example shows that some seemingly rare events are not rare, and they occur
quite often, especially when we get mutiple samples. %The second event has a large probability to occur, because the
%number of possible pairs is much larger.
When you want to see if any of the 23
people has the same birthday as yours, there are only 23 pairs to consider for the event to occur
(comparing your birth date with each of the birth dates of the other people). When you want to see if
any of the 23 people share the same birthday, there are $23\times22/2=253$ possible pairs
(each two persons of the 23) to consider for the event to occur.

This is particularly important in trials, where DNA match is often
used as evidence that a defendant has committed a crime. The chance that a DNA
sample from a particular crime scene matches a random person is extremely low,
but not zero. With nine billion people in the world and many crime scenes, the
probability that some other person's DNA (other than the true offender) matches
the DNA sample from a scene is not negligible.

\begin{listhead}\color{red}
\item [Exercise] Adapt the previous code by changing $N$ and $n$, to check the
  probability that someone will be selected multiple times if you pick a
  name from a list of one million names for one thousand times.
\end{listhead}

\subsection{Predictions}
The following example is one of the earliest questions in probability, when the field was mostly of interest among gamblers (who were also prominent mathematicians).

\begin{example}[Fair Division]
Tom and Jerry each put 30 dollars in a jackpot to start a tennis match. They are
equally good players, and have equal chance to win a match. They decide that the
first one to win three matches will win the \$60.  Now, Tom has won twice and
Jerry has won once, but the matches took a long time and they had to go back
home before a winner was declared. How should they split the 60 dollars, given
the current position (Tom leading 2-1)?
\end{example}

It seems Tom has won twice and Jerry has won once so the 60 dollars should be
split as $40:20$. However, this split is proportional to their current scor, but
it's not proportional to their probabilities of
winning. They need at most another two matches in order to know the final winner. Here are
the four possible winners of the next two matches: \{Tom, Tom\}, \{Tom, Jerry\},
\{Jerry, Tom\}, and \{Jerry, Jerry\}. In the first three possible outcome Tom
ends up with 3 wins, and therefore would get the \$60, and only the fourth
outcome leads to Jerry being the first to reach three wins.
So the probabilities that Tom and Jerry would be the final winner are 3/4 and
1/4, respectively, and thus the fair division should be $45:15$.

Let's use simulation to solve this problem.

\showCode{R}{Code/probability-FairDivision.R}
\runR{Code/probability-FairDivision.R}{FairDivision}{}
Running the above code should give:
\includeOutput{FairDivision}

The takeaway from this example is that it is not sufficient to know what has
happened in the past in order to make accurate predictions. It's also necessary
to know the `horizon' of the experiment (how much longer the experiment needs to
run.) The same logic would apply if the winning probabilities in each match are
not equal, and when the horizon is farther (more matches are needed in order to
declare the winner.)

This can be applied in financial disputes over inheritance. Suppose that Tom and
Jerry are heirs to a big fortune and the go to court, each one hoping to get the
full amount. It may be a lengthy procedure, and maybe at some point they feel
that Tom is leading in the eyes of the judge, but they know that the process may
continue for a long time and they might even die before a decision is made. So,
they can reach a settlement on their own, and avoid the remaining legal
proceedings. This is an oversimplified situation, because there is no clear
score as in a game, but the main idea is that the horizon is as important as the
past in making such decisions.

\hypertarget{Monty-Hall-problem}{%
\subsection{Jumping Probabilities}\label{Monty-Hall-problem}}

\begin{example}[Monty Hall Problem]
Suppose you're on a game show, and you're given the choice of three doors:
Behind one door is a car; behind the others, goats. Whichever door you pick, you
get what's behind it.  You pick a door, say No. 1, and the host, who knows
what's behind the doors, opens another door, say No. 3, which has a goat. He
then says to you, ``Do you want to pick door No. 2?'' Is it to your advantage to
switch your choice?
\end{example}

This famous example has confused many smart people. It's also about conditional
probability and can be solved by using the Bayesian formula. However, setting up
the conditional and unconditional probabilities for this problem is
complicated. Some people did not believe the result answer until they were shown some
simulations. The following code provide a simulation based on \code{n=1000}
repetitions.   

\showCode{R}{Code/probability-MontyHall.R}
\runR{Code/probability-MontyHall.R}{MontyHall}%[run]
Running the above code should give:
\includeOutput{MontyHall}

We see that the probability of winning a car is much higher than 0.5 if one
chooses to switch.

We initially have no information where the prize is, so the probability that the
prize is behind any door is 1/3. Intuition often fails in the second step: when
another door is opened and it contains no prize, most people think that the
total probability has to be divided equally between the two remaining doors. In
other words, the 1/3 probability that we assigned to door 3 has to be divided in
two, and 1/6 will go to the probability of each of doors 1 and 2
(1/3+1/6=1/2). But this is wrong!

Does the fact that we picked initially door 1 (completely by chance) makes any
of the doors special somehow? Strangely, yes!  When we pick door 1 there are two
possibilities -- either it's the winner (with probability 1/3) or it's not. If
it is, then the host can choose either door 2 or door 3 to open (each with
probability 1/2). However, if door 1 is not the winning door, then the host has
no choice. If door 2 is the winner then he must open door 3.  Since we know he
opened door 3, either door 1 is the winner and the host opened door 3 with
probability 1/2 or door 2 is the winner and the host opened door 3 with
probability 1. So, the probability that the host opened door 3 if door 2 is the
winner is twice the probability he opened door 3 if door 1 is the winner.

Notice that this not a consequence of the host trying to trick us, or we having
to perform some reverse psychology and trying to guess what the host
thinks. It's purely a consequence of conditioning on what has already happened
and the information it revealed about the possible future outcome.

\hypertarget{simpsons-paradox}{%
\subsection{Beware of generalizations}\label{simpsons-paradox}}
If we observe a delay in flight take-offs in 8 out of 10 airports, can it be
that overall in the country the average flight takes off on time? If the average
admission rate in a university is greater for women than for men, can it be that
in many (or even most) departments in that university the admission rate for men
is greater than for women? The answer to both these questions, and many similar
scenarios in life, is yes. This phenomenon is called Simpson's paradox.

\begin{example}[Combined percentages]
Tanya and Sonya are two freshmen players in college. In the first 3 games of the
season, Tanya had 11 free throws of which she made 6, and Sonya went 7 times and
made 4 of the free throws.  If at the end of game three the coach want to pick
the player with the best chance of making free throws, who should she choose?

Tanya's probability based on the first three games is $5/11 = .455$, while
Sonya's is $3/7 = .429$, so if the coach picks Tanya the team has a better
chance from the free throws line.

During the next three games, Tanya got 9 free throws and made 6, and Sonya got
14 free throws and made 9.  Again, at the end of game six the coach has to
choose the better free-throw shooter. Based on the last 3 games, Tanya's chances
are $6/9 = .667$, while Sonya's are $9/14 = .643$. So once again, the coach
picks the player with the better chances, and based on the last three games, it
is Tonya once again.

However, if we combine the results from all six games we see that Tanya went to
the line 11+9=20 times and made 11 of the free throws, and Sonya got 7+14=21
free throws and made 3+9=12. So, if we combine the results from all six games
Tonya's percentage from the free throw line is 55\%, while Sonya's is 57.1\%, so
based on the cumulative information Sonya should be the coach's pick!
\end{example}

\begin{example}[UC Berkeley alleged gender bias]
A famous example of Simpson's paradox is a study of gender bias among graduate
school admissions to University of California, Berkeley. In 1973 UC Berkeley was
sued for sex-discrimination. Here are the overall numbers \textit{combined} from
the six largest departments in fall admission of 1973.

\begin{table}[H]
  \begin{tabular*}{\textwidth}{@{\extracolsep{\fill}}crrcrr}
    \toprule
    \multicolumn{3}{c}{Men} & \multicolumn{3}{c}{Women} \\
    \cmidrule(lr){1-3}\cmidrule(lr){4-6}
    Applicants & \multicolumn{2}{c}{Admitted} & Applicants
                                              & \multicolumn{2}{c}{Admitted} \\
    \midrule
    2691 & 1198 & ({\bf 44.5}\%) & 1835 & 557 & (30.4\%) \\
    \bottomrule
  \end{tabular*}
\end{table}

This table shows that men were much more likely than women to be admitted (by
14.1\%). Was there a gender bias? Let's break it down by department (which we
call A--F):

\begin{table}[H]
\begin{tabular*}{\textwidth}{@{\extracolsep{\fill}} ccrrcrr}
  \toprule
  & \multicolumn{3}{c}{Men}  & \multicolumn{3}{c}{Women} \\
  \cmidrule(lr){2-4}\cmidrule(lr){5-7}
  Department & Applicants  & \multicolumn{2}{c}{Admitted} & Applicants
                           & \multicolumn{2}{c}{Admitted} \\
  \midrule
A & 825 & 512& (62\%) & 108 & 89 &(\textbf{82\%})  \\ 
B & 560 & 353& (63\%) & 25  & 17 &(\textbf{68\%})  \\
C & 325 & 120& (37\%) & 593 & 202& (34\%) \\
D & 417 & 138& (33\%) & 375 & 131& (\textbf{35\%}) \\
E & 191 & 53 & (28\%) & 393 & 94 &(24\%)  \\
F & 373 & 22 & (6\%) & 341 & 24 &(\textbf{7\%})  \\
  \bottomrule
\end{tabular*}
\end{table}

Things get strange after we divide the data according different departments. In
four of the departments (A, B, D, and F) women were more likely to be admitted
than men.  In departments C and E, men were more likely to be admitted (by
3-4\%). In contrast, the acceptance rate for women in department A was 20\% more
than for men.

To explain this, \cite{bickel1975sex} noticed that women
tended to \textit{apply} to more competitive departments (C and E) with low admission
rates even among qualified applicants, whereas men tended to apply to
less competitive departments with high admission rates among the
qualified applicants.

So, this is not a case of gender discrimination, but rather, what's called
`confounding bias'. If women were more likely to apply to a competitive
department than men, the overall rejection rate among women can be expected to
be higher.  Consider an extreme example, with department X accepting 1\% of the
applicants, and department Y accepting 50\%. Suppose that 500 women choose to
apply to department X and 500 other women apply to department Y, and suppose
that 1000 men all apply to department Y. Then, department X will have 5 students
(all women) and will reject 495 of the applicants (again, all women). Department
Y, on the other hand will accept 500 men and 250 women. Overall, the acceptance
rate for women is $(5+250)/1000=0.255$, while for men it is $500/1000=0.5$.
\end{example}

Simpson's paradox is not limited to the scenarios of combined percentages or
confounding bias. To illustrate it, we use the following example via
simulations.

\begin{example}[Reverse trends]
We use the following code to simulate data from four groups, each with 40
samples.

\showCode{R}{Code/probability-Simpson.R}[1][6]
\runR{Code/probability-Simpson.R}{Simpson}{}
% Running the above code gives:
% \includeOutput{Simpson}

Next, we plot the whole data and fit a trend equation. Clearly, we see in the
left panels of Figure~\ref{fig:probability-simpson} that as $x$ increases $y$
increases.

\showCode{R}{Code/probability-Simpson.R}[8][9]

If we mark the points by the group to which they belong, and fit a trend line
separately for each group, as $x$ increases $y$ decreases in each and every
group!
\showCode{R}{Code/probability-Simpson.R}[10][12]


\begin{figure}[H]
\includegraphics[width=0.45\textwidth]{images/chapter_3/probability-Simpson-plots.pdf}
\includegraphics[width=0.45\textwidth,page=2]{images/chapter_3/probability-Simpson-plots.pdf}
\caption{Scatter plot of the whole data without (left) and with (right) group labeled}
\label{fig:probability-simpson}
\end{figure}

\end{example}

The three examples all show that we should be very careful when analyzing data
and remember that proportions or trends which are observed in the entire
population may be very different when we break down the data into groups.


\hypertarget{further}{%
\section{Further Examples}\label{further}}

\begin{example}[Henry's Choice\footnote{\url{https://www.braingle.com/brainteasers/20227/loaded-revolver.html}}]
Henry has been caught stealing cattle, and is brought into town for justice. The
judge is his ex-wife Gretchen, who wants to show him some sympathy, but the law
clearly calls for two shots to be taken at Henry from close range. To make
things a little better for Henry, Gretchen tells him she will place two bullets
into a six-chambered revolver in successive order. She will spin the chamber,
close it, and take one shot. If Henry is still alive, she will then either take
another shot, or spin the chamber again before shooting.

Henry is a bit incredulous that his own ex-wife would carry out the punishment,
and a bit sad that she was always such a rule follower. He steels himself as
Gretchen loads the chambers, spins the revolver, and pulls the trigger. Whew! It
was blank. Then Gretchen asks, ``Do you want me to pull the trigger again, or
should I spin the chamber a second time before pulling the trigger?'' What
should Henry choose?
\end{example}

We know that the first chamber Gretchen fired was one of the four empty
chambers. Since the bullets were placed in consecutive order, one of the empty
chambers is followed by a bullet, and the other three empty chambers are
followed by another empty chamber. So if Henry has Gretchen pull the trigger
again, the probability that a bullet will be fired is 1/4.

If Gretchen spins the chamber again, the probability that she shoots Henry would
be 2/6, or 1/3, since there are two possible bullets that would be in firing
position out of the six possible chambers that would be in position.

Let's solve this problem using the following simulation.

\showCode{R}{Code/probability-HenryChoice.R}
\runR{Code/probability-HenryChoice.R}{HenryChoice}{}
Running the above code should give:
\includeOutput{HenryChoice}

% % \hypertarget{prisoners-problem}{%
% \subsection{100 Prisoners Problem}\label{prisoners-problem}%}

The technique of simulation is useful in finding answers in very complicated
problems. Consider the following example modified from
\cite{flajolet2009analytic}.

\begin{example}[100 Prisoners]
In a prison, there are 100 death row prisoners who are numbered from 1
to 100, and there is a room with 100 drawers labeled from 1 to
100. The director randomly puts one prisoner's number in each closed
drawer and offers a last chance. The prisoners enter the room, one
after another. Each prisoner may open and look into 50 drawers in any
order. The drawers are closed again afterwards. If, during this
search, every prisoner finds his number in one of the drawers, all
prisoners are pardoned. If some prisoner does not find his number, all
prisoners die. Before the first prisoner enters the room, the
prisoners may discuss strategy, but they cannot communicate once the
first prisoner enters the room.
\end{example}

The situation is hopeless if every prisoner selects fifty drawers at
random. The probability that a single prisoner finds his number is
0.5, so the probability that all prisoners find their numbers is
$0.5^{100} = 7.89\times10^{-31}\approx0$. However, a better strategy
is given in \citep{stanley2013algebraic}, which is described below:
\begin{enumerate}
\item Each prisoner first opens the drawer with his own number.
\item If this drawer contains his number he is done and was
  successful.
\item Otherwise, the drawer contains the number of another prisoner
  and he next opens the drawer with this number.
\item The prisoner repeats steps 2 and 3 until he finds his own number
  or has opened 50 drawers.
\end{enumerate}

This strategy is better than randomly opening because it utilizes the
information from other prisoners. For example, different prisoners all start
from opening different drawers, while it is almost certain that some prisoners
start from opening the same drawer if they start with a draw at random.

\begin{listhead}
\item [Exercise] Use simulation to find the probability that some prisoners
start from opening the same drawer if they all start with a draw at random.\\
\emph{Hint:} Consider the birthday problem in Example~\ref{exam:birthday}.
\end{listhead}

The probability of survival with the better strategy is complicated to derive
analytically.  In the following, we define two functions to simulate the method
of randomly openning 50 drawers and the better strategy, respectively.

\showCode{R}{Code/probability-100prisoners.R}[1][41]
\runR{Code/probability-100prisoners.R}{100prisoners}
\noindent If we run the following code
\showCode{R}{Code/probability-100prisoners.R}[43][46]
\noindent we should get the following two probabilities for randomly and smartly open the
drawers, respectively:
\includeOutput{100prisoners}

We see that opening drawers randomly has a survival probability of almost zero
while the smart strategy gives a survival probability close to 0.3.

% Axioms?
% inequalities
% football code

\section{Summary}
This chapter covered basic concepts of probability and provided examples on how
probability can help interpret real-life phenomena. Faced with counter-intuitive
and challenging probability problems, we were able to leverage numerical
simulation techniques to gain deeper insights and find solutions easily. Moving
forward, the next chapter will focus on two important probability theorems.

%%% Local Variables:
%%% mode: latex
%%% TeX-command-extra-options: "-shell-escape"
%%% TeX-engine: xetex
%%% TeX-master: "../sidsmain.tex"
%%% End:
