\chapter{Data Collection and Selection Bias}\label{ch:data}
\chapterartfile{images/static/GoodBadSamples.pdf}
  You can't make bricks without straw. Data is necessary to make inference, and
it is important that the data is an unbiased or representative sample of the
population in consideration in order to obtain valid conclusion. This chapter
discusses common sources of biases in the process of data collection, and
introduces some widely used sampling plans and approaches for data collection.

\hypertarget{ch:data}{%
\section{Representative sample}\label{representative}}

In statistics, a population in statistics is the entire set of subjects that we
are interested in studying, and a sample is a subset of a population.  A
representative sample means it reflects the characteristics of the population.
This is important because a main goal of statistical data science is to use the
smaller sample to obtain conclusions on the population.

We use a simulated population to illustrate the concepts with figures. Assume
for a group of people, the weight and height has a relationship
\begin{equation}
  \label{eq:weightheight}
  \text{weight} = -194.49 + 5.30\text{height} + \text{Error},
\end{equation}
where the Error has a normal distribution with mean zero and standard deviation
23.26. We simulate such a population with $N=500$ people and plot their weights
against heights using the following code. The result is given in
Figure~\ref{fig:representativesample} (a).

\showCode{R}{Code/datacollect-goodbadsample.R}[2][7]

Now we use the following code to uniformly and randomly select $n=50$ people as
a sample from the population and marked the selected people in
Figure~\ref{fig:representativesample} (b). We see that the smaller sample of
$n=50$ gives a similar relationship between weight and height as observed in the
larger population of $N=500$. Here the sample is a representative sample. 

\showCode{R}{Code/datacollect-goodbadsample.R}[11][15]

Now, let's assume that the way to take a sample depends on both the weights and
heights in the population. We create a function of weight and height let it
decide the probability of including a person into the sample. The following code
use this way to take a sample and plot it in
Figure~\ref{fig:representativesample} (c). 

\showCode{R}{Code/datacollect-goodbadsample.R}[19][25]

We see that the sample in Figure~\ref{fig:representativesample} (c) does not
reflect the patterns in the population. The heights in the sample is more
clustered around 70, and the relationship between weights and heights in the
sample is dramatically different from that in the population.

\runR{Code/datacollect-goodbadsample.R}{datacollect-goodbadsample}
% \showCode{R}{Code/datacollect-goodbadsample.R}
% \includeOutput{datacollect-goodbadsample}

\begin{figure}
  \centering
    \begin{subfigure}{0.32\textwidth}
      \includegraphics[width=\textwidth]{images/chapter_6/population.pdf}
      \caption{Population}
    \end{subfigure}
  \begin{subfigure}{0.32\textwidth}
      \includegraphics[width=\textwidth]{images/chapter_6/representSample.pdf}
      \caption{Representative sample}
  \end{subfigure}
  \begin{subfigure}{0.32\textwidth}
      \includegraphics[width=\textwidth]{images/chapter_6/biasedSample.pdf}
      \caption{Biased sample}
  \end{subfigure}
  \caption{An illustrative of representative sample}
  \label{fig:representativesample}
\end{figure}

\hypertarget{ch:data}{%
\subsection{A representative sample is more important than a larger sample}\label{representative}}

\begin{example}[The 1936 Literary Digest Poll]
 For the 1936 presidential election, the Literary Digest poll was one of the
largest and most expensive polls with a sample size of around 2.4 million
people. Based on every telephone directory in the United States, lists of
magazine subscribers, rosters of clubs and associations, and other sources, a
mailing list of about 10 million names was created. Every name on this list was
mailed a mock ballot and asked to return the marked ballot to the magazine. The
Literary Digest predicted that Alfred Landon would get 57\% of the vote against
Franklin D. Roosevelt's 43\%, while the actual results were 38\% for Landon
against 62\% for Roosevelt. At the same time, George Gallup was able to predict
a victory for Roosevelt using a much smaller sample of about 50,000 people.

There were two major flaws in the way Literary Digest collect the sample: 1) The
mailing list only contain some subgroups of people in the US. For example,
telephone service was not commonly available in the 1930s; most people might not
belong to any club or other associations. 2) People on the list decided if they
would return the ballot to the magazine, so the resulting sample is a
``volunteer'' sample. In summary, the data collection method of Literary Digest
did not produce a representative sample and thus resulted in a biased estimate
and a misleading conclusion.  
\end{example}

\hypertarget{ch:data}{%
\section{Berkson's bias}\label{berkson-bias}}

The following impressions are common, but are they real facts?
\begin{itemize}
\item Hollywood ruins good books. You can find a lot of good books made into
  terrible movies
  % (e.g., \href{https://www.yardbarker.com/entertainment/articles/popular_books_that_were_made_into_terrible_movies/s1__29971472}{here})
  and a lot of great films made from bad books.
  % (e.g.,
  % \href{https://www.cinelinx.com/movie-news/movie-stuff/bad-books-that-made-great-films/}{here}).
\item Handsome men are such jerks.
\item Pretty girls are meaner.
\item More talented people are less attractive.
\item Smarter students spend less time on studying.
\item The list can go on forever ...
\end{itemize}

The impressions listed above are obtained based on biased data related to
Berkson's bias. Let's start with an example to explain.

\begin{example}[Stumps display]
  Suppose you have 1000 postage stamps: 300 are pretty, 100 are rare, and 30 are
  both pretty and rare. Is a rare stamp more likely to be pretty?  Now you want
  to show some of your stamps to your friends. You probably want to show them
  the pretty ones and the rare ones. Lets say you only show the 370 stamps which
  are either pretty or rare to your friends. Based on what your friends
  observation, will they conclude that a rare stamp more likely to be pretty?
\end{example}

Let's calculate some numbers to see the answer. For all the stamps, the
probability that a stamp is pretty is 300/1000=0.3; for rare stamps, the
probability that a stamp is pretty is 30/100=0.3. Thus, a rare stamp is not less
likely to be pretty.

For the stamps your friends saw, the probability that a stamp is pretty is
300/370=0.81; for rare stamps, the probability that a stamp is pretty is
30/100=0.3. Your friends' conclusion would be: a rare stamp is much less likely
to be pretty!

The reason for their incorrect conclusion is that the 370 stumps are not a
representative sample of all the stamps you have. The sample is biased.

Now let's simulate some data to further illustrate the problem.

\showCode{R}{Code/datacollect-berkson.R} %
\runR{Code/datacollect-berkson.R}{datacollect-berkson} %
Running the above code should give the two figures in Figure~\ref{fig:berkson}
and the following output.
\includeOutput{datacollect-berkson} %
We see from the output and Figure~\ref{fig:berkson} that the correlation between
the goodness of books and the goodness of movies is very close to zero and there
is no linear association between them. However, if we only see the good books or
good movies (a biased sample), the negative linear relationship is very evident
in Figure~\ref{fig:berkson} (b) and the correlation has a large
magnitude. People typically only recommend good books or good movies to other
people, so what we see are only these with some good characters. If a book is
bad and the movie based on it is terrible, it is very likely that you never have
a chance to know them. Thus, the impression that Hollywood ruins good books is
not a real fact, but just an impression based on a biased sample. This explains
other impressions on the previous list as well.

\begin{figure}[H]
  \begin{subfigure}{0.485\textwidth}
    \includegraphics[width=\textwidth]{images/chapter_6/berkson1.pdf}
    \caption{No linear association between goodness of movies and goodness of
      books}
  \end{subfigure}
  \begin{subfigure}{0.485\textwidth}
    \includegraphics[width=\textwidth]{images/chapter_6/berkson2.pdf}
    \caption{Negative linear association for top 10 percent books and/or movies}
  \end{subfigure}
  \caption{Goodness of movies v.s. goodness of books}
  \label{fig:berkson}
\end{figure}

\hypertarget{ch:data}{%
\section{Survival Bias}\label{survival-bias}}
Having cautioned about so-­called survivor bias in financial indexes, it is
worth noting that ­things can be more complicated.  Taking hedge funds as an
example, certainly, poorly performing funds are likely to close and not be
included in the data, but so also are funds at the opposite end of the spectrum:
exception- ally strongly performing funds are likely to close to new inves-
tors. Likewise, strongly performing companies can split and so drop out of a
share index. Dark data can work in mysterious ways.  Additionally, for reasons
we ­shall explore in chapter 3, ­there is a good chance funds which have
performed exceptionally well in the past will nosedive in the f­ uture owing to
the phenomenon of “regression to the mean.” This means purchasers of funds need
to look very carefully at how past per­for­mance is evaluated. As in other walks
of life, investors need to ask themselves if the truth is being disguised by
invisible dark data.

Survivor bias is always a potential prob­lem for ­things which change over
time. In the world of startups we tend to hear more about the successes than the
failures—­even though the major- ity of such companies fail. Some researchers
put this failure rate as low as 50 ­percent, while o­ thers put it as high as 99 ­percent. Of
course, it partly depends on the time period you are consider-
ing (one year, 50 years?) and how you define “failure.” Take the
social networking site Bebo, for example. Launched in 2005, at
one stage Bebo was the most popu­lar social networking site in
the UK, with nearly 11 million users. In 2008 it was bought by
AOL for $850 million. So, over a three-­year horizon Bebo was
hugely successful. But then the number of users started to fall,
partly as they shifted to Facebook, and in 2010 AOL sold Bebo
to Criterion Capital Partners. A computer glitch damaged its
reputation, and in 2013 Bebo filed for Chapter 11 bankruptcy pro-
tection. ­Later in 2013 the original found­ers, Michael and Xochi
Birch, bought the com­pany back for $1 million. So is this a suc-
cess or a failure? And what about Lehman ­Brothers? This firm
was founded in 1850 and became the fourth largest investment
bank in the United States—­until it filed for bankruptcy in 2008,
that is. Like Bebo, the com­pany came to a sticky end, albeit over
a longer time interval. But was it a success or a failure?

In the startup world p­ eople would naturally like to hear about
the success stories more than about the failure stories, simply
­because they are trying to emulate the successes and not the fail-
ures. But this situation reveals another kind of dark data. What
entrepreneurs should be looking for are characteristics which
distinguish between successes and failures, not simply character-
istics which happen to have been associated with successes.
Characteristics of the latter kind might also be associated with
the failures. Moreover, even if the characteristics are associated
with successes more than failures, ­there is no guarantee they are
causal.

https://xkcd.com/1827/

The wonderful comic website xkcd has a cartoon about sur-
vivor bias.9 The character is advising us never to stop buying lot-
tery tickets, describing how he lost and lost time ­after time but
kept buying tickets, even taking extra jobs to earn money to buy
more tickets. And he eventually succeeded (if “succeeded” is the
right word). What we d­ on’t see are the gamblers who poured
fortunes into lottery tickets but died without winning.

In general, administrative data have im­mense potential to do
good, provided we appreciate the dark data risks. But ­there is a
complementary aspect which might be less positive that is lead-
ing to increasing concern.

From our individual perspective the data exhaust retained in
an administrative data database is a data shadow. It consists of
the traces we leave from sending emails or texts, tweeting, post-
ing a comment on YouTube, swiping credit cards, using travel
cards, making phone calls, updating a social media app, logging
onto a computer or iPad, taking cash from an ATM, driving past
a car license plate recognition camera, and so on endlessly, in
often unsuspected ways. While such data can indeed be aggre-
gated to benefit society, they also inevitably reveal a huge amount
about each of us as individuals, our likes and dislikes, and our
habits and be­hav­iors. The data relating to us as individuals can
be used to our benefit—­guiding us t­ oward products or events
which might interest us, facilitating travel, and generally smooth-
ing life out for us. But they can also be used to manipulate be­
hav­ior. Authoritarian regimes can exert considerable control over
us if they know detailed patterns of our lives. In a way this is in-
evitable: the downside of giving out information so that we can
be assisted is that . . . ​we give out information.

­Because of increasing concern about data shadows, ser­vices
exist which ­will minimize our shadow. Or, from the perspective
of this book, ser­vices exist to switch off the light on data, render-
ing them dark. Basic steps include deactivating all social media
accounts (Facebook, Twitter, ­etc.), deleting old email accounts,
deleting search results, using false information for accounts we
cannot delete (e.g., false birth dates or ­middle initials), unsub-
scribing from lists and alerts, and so on. Of course, the comple-
mentary side of the protection created by hiding data is that the
potential benefits ­will be adversely impacted. We can determine
whom to give tax credits to only if we have details of ­people’s
income and tax payments.


For example, in a study comparing an active treatment with
a placebo (a “treatment” believed to have no active therapeutic
ingredient) any side effects are more likely to occur with the ac-
tive treatment, since, by definition, the placebo has no active
component. This may well mean that dropouts arise more often
in the treatment group. Perhaps worse, if ­people who see no ben-
efit or even deteriorate are more likely to drop out, then the
study ­will be disproportionately left with ­those who do see a ben-
efit. If we d­ on’t allow for the dropouts in some way, we can
obtain a highly misleading impression of the effectiveness of the
treatment. This is another example of survivor bias—­those who
“survive” or continue to the end of the trial do not properly rep-
resent the effect on the entire group.

As a final financial index example, in chapter 2 we saw that
survivor bias affected not only the Dow Jones and S\&P 500 but
also hedge fund indexes. The Barclay Hedge Fund Index is based
on the arithmetic mean of the net returns of the hedge funds
listed in the Barclay database. But funds whose per­for­mance has
deteriorated to the extent they have been closed ­will not be in-
cluded t­ here. Once again, though, the deteriorating per­for­
mance should be apparent in the months leading up to the clo-
sure, so ­these data may also be SDD.

A. L. Barrett and B. R. Brodeski, “Survivorship bias and improper mea­sure­ment:
How the mutual fund industry inflates actively managed fund per­for­mance” (Rock-
ford, IL:
% Savant Capital Management, Inc., March 2006), http://­www​.­google​.­co​.­uk​
% /­url​?­sa​=­t&rct​= ­j&q​=­&esrc​=­s&source​=­web&cd​=­1&ved​=­0ahUKEwiavpGPz6zYAh
% W F J M A K H a K a B N Q Q Fg g p M A A & u r l​ =­h t t p % 3 A % 2 F % 2 F w w w​ .­e t f​
% .­com%2Fdocs%2Fsbiasstudy.​ ­pdf&usg=
% ​ ­AOvVaw2nPmIjOOE1iWk2CByyeClw, ac-
cessed 28 December 2017.



Survival bias often occurs when subjects or objects can be observed only if they
have survived or completed a certain process. Ignoring the survival bias may lead
to inaccurate or opposite conclusions.

\begin{example}[hit aircraft]
During World War II, aircraft that had returned from missions were examined and
the most-hit areas of the plane are given in
Figure~\ref{fig:survival-bias}. Which areas should the army add armor to
increase the survivorship of the planes?

A direct intuition may suggest to reinforce areas with the most bullet holes
because these are the most hit region. However, the data were collected from the
aircraft that had survived their missions, and if an aircraft was hit and down
it would not be included in the data. If there is a bullet hole in the engine
area or in the cockpit, then it would unlikely that the aircraft could
return. This was actually the reason why the engine and cockpit regions were
almost free of bullet holes. Knowing that the marked dots for bullets holes were
a biased sample and the cause of the bias, we should realized that these regions
with bullet holes could take damage and the aircraft could still fly well enough
to return safely. These regions did not need additional armor. It is the areas
where the returning aircraft were unscathed that need additional armor.
\end{example}

This example shows that ignoring the bias may give a very wrong conclusion. If
we take into account the source of the bias, then we can still obtain valid
result from a biased sample.

% the statistician Abraham Wald took survivorship bias into his calculations when considering how to minimize bomber losses to enemy fire.[11] The Statistical Research Group (SRG) at Columbia University, which Wald was a part of, examined the damage done to aircraft that had returned from missions and recommended adding armor to the areas that showed the least damage, based on his reasoning.
% This contradicted the US military's conclusions that the most-hit areas of the plane needed additional armor.[12][13][14] Wald noted that the military only considered the aircraft that had survived their missions; any bombers that had been shot down or otherwise lost had logically also been rendered unavailable for assessment. The bullet holes in the returning aircraft, then, represented areas where a bomber could take damage and still fly well enough to return safely to base. Thus, Wald proposed that the Navy reinforce areas where the returning aircraft were unscathed,[11]:88 since those were the areas that, if hit, would cause the plane to be lost. His work is considered seminal in the then-nascent discipline of operational research.[15]

\begin{figure}[H]
  \includegraphics[width=\textwidth]{images/static/Survivorship-bias.png}
  \caption{Most-hit areas of the returned aircraft. Source: \url{https://en.wikipedia.org/wiki/Survivorship_bias}}
  \label{fig:survival-bias}
\end{figure}

\hypertarget{ch:data}{%
  \section{Common biases}\label{sources-bias}}
Here is a list of common biases and their sources.
\begin{itemize}
\item Observation time interval bias. it is caused by early termination of a
trial or experiment at a time when its results support the desired
conclusion. This is closely related to the next confirmation bias.
\item Confirmation bias occurs when people tries to search for, interpret, favor, and recall information in a way that confirms or supports one's prior beliefs or values. A famous is cherry picking. 
  The picker would be expected to select only the ripest and healthiest fruits.
  Thus the resulting picked cherries represent the condition of the good fruit
  in the garden instead of the condition for all the fruit in the garden. 
\item Data partition bias is caused by dividing data with knowledge of the contents of the partitions. 
\item Rejection of bad data on arbitrary grounds instead of according to
  previously stated or generally agreed criteria also cause biases. Another
  closely related scenario is to discard ``outliers'' without valid reasons.
\item Self-selection bias or a volunteer bias happens when objects in
  consideration decide on their own if they will be included in a
  sample. Volunteers tend to have intrinsically different characteristics from
  the whole population of people in consideration. 
\item Nonresponse bias means the bias caused by subjects not answering relevant
  questions. It is often related to sensitive questions.
\end{itemize}

\hypertarget{ch:data}{%
  \section{Basic sampling designs}\label{sampling-designs}}
There are three basic sampling designs. Most of advanced and complicated
sampling designs are developed by combing these basic designs in layers.
\begin{itemize}
\item Simple Random Sampling: Every elements in the target population have equal
  chances to be selection. Samples are selected strictly by chance. It is
  probably the most effective method to prevent sampling bias. A disadvantage is
  the uncertainty may be large.
\item Stratified Sampling: Divide members of the population into homogeneous
  subgroups and then use simple random sampling for each subgroups. It helps to
  reduce the uncertainty. Need to be careful of potential biases.
\item Weighted Sampling: Let more informative elements have higher chances to be
  selected. It may increase the estimation efficiency, but the resulting sample
  may be biased so need special way of estimation.
\end{itemize}

% \hypertarget{ch:data}{%
%   \section{Different sampling approaches}\label{sampling-approaches}}
% %%%%----------------------------------------------------------
%   \begin{itemize}
%   \item Sampling with replacement: An element may be included in a sample more than once. It is possible to have replicates in the sample.
%   \item Sampling without replacement: An element can be included in a sample at most once. There is no replicates in the sample.
%   \item Poisson sampling: determines if each element of the population is selected in the sample independently. The sample size is random.
%   \item Between Sampling with replacement and without replacement, which is more efficient?
%   \end{itemize}

% %%%%----------------------------------------------------------
% \begin{example}[Numerical comparisons]
%   \begin{itemize}
%   \item To simulation hosehold incomes, generate a population P of size $N$ from a $P\sim\chi^2$ distribution with degrees of freedom one.
%   \item Take samples of size $n$ from P to estimator the population mean, say $\mu$, using simple random sampling both with and without replacement. Compare their efficiency.
%   \item Assume another variable $A=P+Unif(0,2)$ is available to define informative sampling weights. Evaluate the efficiency of weighted sampling both with and without replacement. 
%   \end{itemize}
% \end{example}

\section{Summary}
This chapter introduced the basic concept of a representative sample and
illustrated that understanding bias helps to interpret unusual phenomena. It
also showed that valid conclusion could be made based on biased samples. 

%%% Local Variables:
%%% mode: latex
%%% TeX-command-extra-options: "-shell-escape"
%%% TeX-engine: xetex
%%% TeX-master: "../sidsmain.tex"
%%% End:
