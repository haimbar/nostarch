\chapter{Data Collection and Selection Bias}\label{ch:data}
\chapterartfile{images/static/GoodBadSamples.pdf}
  You can't make bricks without straw. Data is necessary to make inference, and
it is important that the data is an unbiased or representative sample of the
population in consideration in order to obtain valid conclusion. This chapter
discusses common sources of biases in the process of data collection, and
introduces some widely used sampling plans and approaches for data collection.

\hypertarget{ch:data}{%
\section{Representative sample}\label{representative}}

In statistics, a population in statistics is the entire set of subjects that we
are interested in studying, and a sample is a subset of a population.  A
representative sample means it reflects the characteristics of the population.
This is important because a main goal of statistical data science is to use the
smaller sample to obtain conclusions on the population.

We use a simulated population to illustrate the concepts with figures. Assume
for a group of people, the weight and height has a relationship
\begin{equation}
  \label{eq:weightheight}
  \text{weight} = -194.49 + 5.30\text{height} + \text{Error},
\end{equation}
where the Error has a normal distribution with mean zero and standard deviation
23.26. We simulate such a population with $N=500$ people and plot their weights
against heights using the following code. The result is given in
Figure~\ref{fig:representativesample} (a).

\showCode{R}{Code/datacollect-goodbadsample.R}[2][7]

Now we use the following code to uniformly and randomly select $n=50$ people as
a sample from the population and marked the selected people in
Figure~\ref{fig:representativesample} (b). We see that the smaller sample of
$n=50$ gives a similar relationship between weight and height as observed in the
larger population of $N=500$. Here the sample is a representative sample. 

\showCode{R}{Code/datacollect-goodbadsample.R}[11][15]

Now, let's assume that the way to take a sample depends on both the weights and
heights in the population. We create a function of weight and height let it
decide the probability of including a person into the sample. The following code
use this way to take a sample and plot it in
Figure~\ref{fig:representativesample} (c). 

\showCode{R}{Code/datacollect-goodbadsample.R}[19][25]

We see that the sample in Figure~\ref{fig:representativesample} (c) does not
reflect the patterns in the population. The heights in the sample is more
clustered around 70, and the relationship between weights and heights in the
sample is dramatically different from that in the population.

\runR{Code/datacollect-goodbadsample.R}{datacollect-goodbadsample}
% \showCode{R}{Code/datacollect-goodbadsample.R}
% \includeOutput{datacollect-goodbadsample}

\begin{figure}
  \centering
    \begin{subfigure}{0.32\textwidth}
      \includegraphics[width=\textwidth]{images/chapter_6/population.pdf}
      \caption{Population}
    \end{subfigure}
  \begin{subfigure}{0.32\textwidth}
      \includegraphics[width=\textwidth]{images/chapter_6/representSample.pdf}
      \caption{Representative sample}
  \end{subfigure}
  \begin{subfigure}{0.32\textwidth}
      \includegraphics[width=\textwidth]{images/chapter_6/biasedSample.pdf}
      \caption{Biased sample}
  \end{subfigure}
  \caption{An illustrative of representative sample}
  \label{fig:representativesample}
\end{figure}

\hypertarget{ch:data}{%
\subsection{A representative sample is more important than a larger sample}\label{representative}}

\begin{example}[The 1936 Literary Digest Poll]
 For the 1936 presidential election, the Literary Digest poll was one of the
largest and most expensive polls with a sample size of around 2.4 million
people. Based on every telephone directory in the United States, lists of
magazine subscribers, rosters of clubs and associations, and other sources, a
mailing list of about 10 million names was created. Every name on this list was
mailed a mock ballot and asked to return the marked ballot to the magazine. The
Literary Digest predicted that Alfred Landon would get 57\% of the vote against
Franklin D. Roosevelt's 43\%, while the actual results were 38\% for Landon
against 62\% for Roosevelt. At the same time, George Gallup was able to predict
a victory for Roosevelt using a much smaller sample of about 50,000 people.

There were two major flaws in the way Literary Digest collect the sample: 1) The
mailing list only contain some subgroups of people in the US. For example,
telephone service was not commonly available in the 1930s; most people might not
belong to any club or other associations. 2) People on the list decided if they
would return the ballot to the magazine, so the resulting sample is a
``volunteer'' sample. In summary, the data collection method of Literary Digest
did not produce a representative sample and thus resulted in a biased estimate
and a misleading conclusion.  
\end{example}

\hypertarget{ch:data}{%
\section{Berkson's bias}\label{berkson-bias}}

The following impressions are common, but are they real facts?
\begin{itemize}
\item Hollywood ruins good books. You can find a lot of good books made into
  terrible movies
  % (e.g., \href{https://www.yardbarker.com/entertainment/articles/popular_books_that_were_made_into_terrible_movies/s1__29971472}{here})
  and a lot of great films made from bad books.
  % (e.g.,
  % \href{https://www.cinelinx.com/movie-news/movie-stuff/bad-books-that-made-great-films/}{here}).
\item Handsome men are such jerks.
\item Pretty girls are meaner.
\item More talented people are less attractive.
\item Smarter students spend less time on studying.
\item The list can go on forever ...
\end{itemize}

The impressions listed above are obtained based on biased data related to
Berkson's bias. Let's start with an example to explain.

\begin{example}[Stumps display]
  Suppose you have 1000 postage stamps: 300 are pretty, 100 are rare, and 30 are
  both pretty and rare. Is a rare stamp more likely to be pretty?  Now you want
  to show some of your stamps to your friends. You probably want to show them
  the pretty ones and the rare ones. Lets say you only show the 370 stamps which
  are either pretty or rare to your friends. Based on what your friends
  observation, will they conclude that a rare stamp more likely to be pretty?
\end{example}

Let's calculate some numbers to see the answer. For all the stamps, the
probability that a stamp is pretty is 300/1000=0.3; for rare stamps, the
probability that a stamp is pretty is 30/100=0.3. Thus, a rare stamp is not less
likely to be pretty.

For the stamps your friends saw, the probability that a stamp is pretty is
300/370=0.81; for rare stamps, the probability that a stamp is pretty is
30/100=0.3. Your friends' conclusion would be: a rare stamp is much less likely
to be pretty!

The reason for their incorrect conclusion is that the 370 stumps are not a
representative sample of all the stamps you have. The sample is biased.

Now let's simulate some data to further illustrate the problem.

\showCode{R}{Code/datacollect-berkson.R} %
\runR{Code/datacollect-berkson.R}{datacollect-berkson} %
Running the above code should give the two figures in Figure~\ref{fig:berkson}
and the following output.
\includeOutput{datacollect-berkson} %
We see from the output and Figure~\ref{fig:berkson} that the correlation between
the goodness of books and the goodness of movies is very close to zero and there
is no linear association between them. However, if we only see the good books or
good movies (a biased sample), the negative linear relationship is very evident
in Figure~\ref{fig:berkson} (b) and the correlation has a large
magnitude. People typically only recommend good books or good movies to other
people, so what we see are only these with some good characters. If a book is
bad and the movie based on it is terrible, it is very likely that you never have
a chance to know them. Thus, the impression that Hollywood ruins good books is
not a real fact, but just an impression based on a biased sample. This explains
other impressions on the previous list as well.

\begin{figure}[H]
  \begin{subfigure}{0.485\textwidth}
    \includegraphics[width=\textwidth]{images/chapter_6/berkson1.pdf}
    \caption{No linear association between goodness of movies and goodness of
      books}
  \end{subfigure}
  \begin{subfigure}{0.485\textwidth}
    \includegraphics[width=\textwidth]{images/chapter_6/berkson2.pdf}
    \caption{Negative linear association for top 10 percent books and/or movies}
  \end{subfigure}
  \caption{Goodness of movies v.s. goodness of books}
  \label{fig:berkson}
\end{figure}

\hypertarget{ch:data}{%
\section{Survival Bias}\label{survival-bias}}
Survival bias often occurs when subjects or objects can be observed only if they
have survived or completed a certain process. Ignoring the survival bias may lead
to inaccurate or opposite conclusions.

\begin{example}[hit aircraft]
During World War II, aircraft that had returned from missions were examined and
the most-hit areas of the plane are given in
Figure~\ref{fig:survival-bias}. Which areas should the army add armor to
increase the survivorship of the planes?

A direct intuition may suggest to reinforce areas with the most bullet holes
because these are the most hit region. However, the data were collected from the
aircraft that had survived their missions, and if an aircraft was hit and down
it would not be included in the data. If there is a bullet hole in the engine
area or in the cockpit, then it would unlikely that the aircraft could
return. This was actually the reason why the engine and cockpit regions were
almost free of bullet holes. Knowing that the marked dots for bullets holes were
a biased sample and the cause of the bias, we should realized that these regions
with bullet holes could take damage and the aircraft could still fly well enough
to return safely. These regions did not need additional armor. It is the areas
where the returning aircraft were unscathed that need additional armor.
\end{example}

This example shows that ignoring the bias may give a very wrong conclusion. If
we take into account the source of the bias, then we can still obtain valid
result from a biased sample.

% the statistician Abraham Wald took survivorship bias into his calculations when considering how to minimize bomber losses to enemy fire.[11] The Statistical Research Group (SRG) at Columbia University, which Wald was a part of, examined the damage done to aircraft that had returned from missions and recommended adding armor to the areas that showed the least damage, based on his reasoning.
% This contradicted the US military's conclusions that the most-hit areas of the plane needed additional armor.[12][13][14] Wald noted that the military only considered the aircraft that had survived their missions; any bombers that had been shot down or otherwise lost had logically also been rendered unavailable for assessment. The bullet holes in the returning aircraft, then, represented areas where a bomber could take damage and still fly well enough to return safely to base. Thus, Wald proposed that the Navy reinforce areas where the returning aircraft were unscathed,[11]:88 since those were the areas that, if hit, would cause the plane to be lost. His work is considered seminal in the then-nascent discipline of operational research.[15]

\begin{figure}[H]
  \includegraphics[width=\textwidth]{images/static/Survivorship-bias.png}
  \caption{Most-hit areas of the returned aircraft. Source: \url{https://en.wikipedia.org/wiki/Survivorship_bias}}
  \label{fig:survival-bias}
\end{figure}

\hypertarget{ch:data}{%
  \section{Common biases}\label{sources-bias}}
Here is a list of common biases and their sources.
\begin{itemize}
\item Observation time interval bias. it is caused by early termination of a
trial or experiment at a time when its results support the desired
conclusion. This is closely related to the next confirmation bias.
\item Confirmation bias occurs when people tries to search for, interpret, favor, and recall information in a way that confirms or supports one's prior beliefs or values. A famous is cherry picking. 
  The picker would be expected to select only the ripest and healthiest fruits.
  Thus the resulting picked cherries represent the condition of the good fruit
  in the garden instead of the condition for all the fruit in the garden. 
\item Data partition bias is caused by dividing data with knowledge of the contents of the partitions. 
\item Rejection of bad data on arbitrary grounds instead of according to
  previously stated or generally agreed criteria also cause biases. Another
  closely related scenario is to discard ``outliers'' without valid reasons.
\item Self-selection bias or a volunteer bias happens when objects in
  consideration decide on their own if they will be included in a
  sample. Volunteers tend to have intrinsically different characteristics from
  the whole population of people in consideration. 
\item Nonresponse bias means the bias caused by subjects not answering relevant
  questions. It is often related to sensitive questions.
\end{itemize}

\hypertarget{ch:data}{%
  \section{Basic sampling designs}\label{sampling-designs}}
There are three basic sampling designs. Most of advanced and complicated
sampling designs are developed by combing these basic designs in layers.
\begin{itemize}
\item Simple Random Sampling: Every elements in the target population have equal
  chances to be selection. Samples are selected strictly by chance. It is
  probably the most effective method to prevent sampling bias. A disadvantage is
  the uncertainty may be large.
\item Stratified Sampling: Divide members of the population into homogeneous
  subgroups and then use simple random sampling for each subgroups. It helps to
  reduce the uncertainty. Need to be careful of potential biases.
\item Weighted Sampling: Let more informative elements have higher chances to be
  selected. It may increase the estimation efficiency, but the resulting sample
  may be biased so need special way of estimation.
\end{itemize}

% \hypertarget{ch:data}{%
%   \section{Different sampling approaches}\label{sampling-approaches}}
% %%%%----------------------------------------------------------
%   \begin{itemize}
%   \item Sampling with replacement: An element may be included in a sample more than once. It is possible to have replicates in the sample.
%   \item Sampling without replacement: An element can be included in a sample at most once. There is no replicates in the sample.
%   \item Poisson sampling: determines if each element of the population is selected in the sample independently. The sample size is random.
%   \item Between Sampling with replacement and without replacement, which is more efficient?
%   \end{itemize}

% %%%%----------------------------------------------------------
% \begin{example}[Numerical comparisons]
%   \begin{itemize}
%   \item To simulation hosehold incomes, generate a population P of size $N$ from a $P\sim\chi^2$ distribution with degrees of freedom one.
%   \item Take samples of size $n$ from P to estimator the population mean, say $\mu$, using simple random sampling both with and without replacement. Compare their efficiency.
%   \item Assume another variable $A=P+Unif(0,2)$ is available to define informative sampling weights. Evaluate the efficiency of weighted sampling both with and without replacement. 
%   \end{itemize}
% \end{example}

%%% Local Variables:
%%% mode: latex
%%% TeX-command-extra-options: "-shell-escape"
%%% TeX-engine: xetex
%%% TeX-master: "../sidsmain.tex"
%%% End:
